import argparse
import json
import pathlib
import re
import sys
from collections import defaultdict
from collections.abc import Iterable
from dataclasses import dataclass
from functools import cached_property, partial

compact_json = partial(json.dumps, separators=(",", ":"))


@dataclass(frozen=True)
class Scale:
    name: str
    semis: list[int]

    def as_dict(self):
        return {"name": self.name, "semis": self.semis}

    @cached_property
    def semis_key(self) -> str:
        return ";".join(sorted(str(s) for s in self.semis))


ScalesDict = dict[str, list[Scale]]


def convert_reascale(reascale_data: str) -> Iterable[tuple[str, Scale]]:
    current_group_name = None

    for line in reascale_data.splitlines():
        if line.startswith("#"):
            continue

        if line.startswith("2"):  # start-of-group
            m = re.match(r'^2\s+"(.+?)"', line)
            if m:
                current_group_name = m.group(1)
            continue

        if line.startswith("-2"):  # end-of-group
            current_group_name = None
            continue

        if line.startswith("0"):  # scale
            m = re.match(r'^0\s+"(.+?)"\s+([0-9]+)', line)
            if m:
                semis = [index for index, c in enumerate(m.group(2)) if c != "0"]
                group_name = current_group_name or "Ungrouped"
                yield group_name, Scale(name=m.group(1), semis=semis)


def data_to_code(data):
    code = "/* this file is autogenerated by reascale-js/convert-cli */\nmodule.exports = {\n"
    for group_name, group_data in data.items():
        code += f"  {compact_json(group_name)}: [\n"
        for scale in sorted(group_data, key=lambda scale: scale.name):
            code += f"    {compact_json(scale.as_dict())},\n"
        code += "  ],\n"
    code += "};"
    return code


def data_to_json(data):
    return compact_json(
        {
            group_name: [
                scale.as_dict()
                for scale in sorted(group_data, key=lambda scale: scale.name)
            ]
            for group_name, group_data in sorted(data.items())
        }
    )


def gather_omnibus(file_datas: list[ScalesDict]):
    seen = set()
    omnibus_groups = defaultdict(list)
    for data in file_datas:
        for group_name, group_data in data.items():
            for scale in group_data:
                if scale.semis_key not in seen:
                    seen.add(scale.semis_key)
                    omnibus_groups[group_name].append(scale)
    return omnibus_groups


def run():
    ap = argparse.ArgumentParser()
    ap.add_argument("--dest-dir", default="out/", type=pathlib.Path)
    ap.add_argument("--single-files", action="store_true")
    ap.add_argument("--omnibus-js", type=pathlib.Path)
    ap.add_argument("--omnibus-json", type=pathlib.Path)
    ap.add_argument("files", nargs="*", type=pathlib.Path)
    args = ap.parse_args()

    if not args.files:
        sys.stderr.write("Reading reascale from stdin and writing JS to stdout.\n")
        text = sys.stdin.read()
        data = convert_reascale(text)
        code = data_to_code(data)
        sys.stdout.write(code)
        sys.exit(0)

    dest_dir: pathlib.Path = args.dest_dir
    file_datas: list[ScalesDict] = []
    src_path: pathlib.Path
    for src_path in args.files:
        text = src_path.read_text()
        data = defaultdict(list)
        for group, scale in convert_reascale(text):
            data[group].append(scale)
        if args.single_files:
            dest_filename = dest_dir / src_path.with_suffix(".js").name
            dest_filename.write_text(data_to_code(data))
            print(f"Single file OK: {src_path} --> {dest_filename}")
        file_datas.append(data)

    omnibus_data = gather_omnibus(file_datas)
    if args.omnibus_js:
        args.omnibus_js.write_text(data_to_code(omnibus_data))
        print(f"Omnibus JS OK: {args.omnibus_js}")
    if args.omnibus_json:
        args.omnibus_json.write_text(data_to_json(omnibus_data))
        print(f"Omnibus JSON OK: {args.omnibus_json}")


if __name__ == "__main__":
    run()
